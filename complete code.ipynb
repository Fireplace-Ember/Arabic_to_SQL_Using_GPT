{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "import pandas as pd\n",
    "\n",
    "###innitiate values that are shuffled around for more varied prompts and sql queries\n",
    "\n",
    "template=pd.read_excel(r\"C:\\...\\templateText.xlsx\")#here the code accesses the template containing the natural language phrases\n",
    "templatesql=pd.read_excel(r\"C:\\...\\templateSQL.xlsx\")#here the code accessed the template with the corresponding SQL commands\n",
    "countryList=pd.read_excel(r\"C:\\...\\countries.xlsx\")#here the list of the countries used is accessed\n",
    "listdecide = ['اقل من', \"اكثر من\", \"اعلى من\", \"ارخص من\", \"اغلى من\", \"يقارب\"]#here the types of compares are accessed (less than, more than...)\n",
    "listdecidesql = ['< X4', '> X4', '\\t > X4', '\\t < X4', '\\t > X4', 'BETWEEN 50 + X4 AND X4 -50']#here are the corresponding comparsions\n",
    "X6Text = \"في يوم X6\"#here is the general format for date in the nl prompt. Placing it here increases the variaty of prompts generated\n",
    "\n",
    "###innitiate data holders\n",
    "newdata = pd.DataFrame()\n",
    "newsql=pd.DataFrame()\n",
    "full =[]#used for testing, debugging, and length control\n",
    "\n",
    "\n",
    "\n",
    "while (len(full)  <700):#number of elements\n",
    " X6Text = \" في يوم X6\"\n",
    " date = \"'\"+str(rd.randint(1,28)) + '-' + str(rd.randint(1,12)) + '-' + str(rd.randint(2021,2023))+\"'\"#select random date\n",
    " X6Sql = \"AND 'اليوم'==\"+date+\" \"#create the argument to find date\n",
    " X6Text = X6Text.replace('X6', date)#create the text argument to add to the prompt\n",
    "\n",
    " priceindex = rd.randint(0,len(listdecide)-1) #needed to select the comparsion type\n",
    " location1 = countryList.loc[rd.randint(0,len(countryList)-1),:].item()#extract destination\n",
    " location2 = countryList.loc[rd.randint(0,len(countryList)-1),:].item()#extract starting location\n",
    " price = str(rd.randint(100,500))#range of price depends on data.\n",
    " pricechoice = listdecide[priceindex]#decide on what type of price comparsion\n",
    " pricechoicesql = listdecidesql[priceindex]#needed for the \"between\" argument\n",
    " degree = str(rd.randint(1,4))#seat degree (1st class, 2nd class, etc...)\n",
    "\n",
    " deciderDate = rd.randint(1,100)/100 #the probability of including a date in the final argument\n",
    "\n",
    "\n",
    "\n",
    " while location1 == location2:#checks that destination and start are not the same\n",
    "    location2 = countryList.loc[rd.randint(0,len(countryList)-1),:].item()#look for another location if two are equal\n",
    " \n",
    " randomindex = rd.randint(0,len(template)-1)#shuffles and selects \"base phrase\" from the template at random\n",
    " sqls =  templatesql.iloc[randomindex,:]\n",
    " sqls = sqls.str.replace('Y2' ,  \"'البداية'\")#to\n",
    " sqls = sqls.str.replace('Y1', \"'الوجهة'\")#from\n",
    " sqls = sqls.str.replace('Y3 ', \"'التكلفة'\") #price in dollars\n",
    " sqls = sqls.str.replace('Y5', \"'الدرجة'\") #price in dollars\n",
    " \n",
    " sqls= sqls.str.replace('X1' ,  \"'\"+location1+\"'\")#to\n",
    " sqls = sqls.str.replace('X2', \"'\"+location2+\"'\")#from\n",
    " sqls = sqls.str.replace('X3', pricechoicesql) #cheaper/> expensive\n",
    " sqls = sqls.str.replace('X4', price) #price in dollars\n",
    " sqls = sqls.str.replace('X5', \"'\"+degree+\"'\")\n",
    " \n",
    " \n",
    "\n",
    "\n",
    " Item =  template.iloc[randomindex,:]\n",
    " Item= Item.str.replace('X1' ,  location1)#to\n",
    " Item = Item.str.replace('X2', location2)#from\n",
    " Item = Item.str.replace('X4', price) #price in dollars\n",
    " Item = Item.str.replace('X3', pricechoice) #cheaper/> expensive\n",
    " Item = Item.str.replace('X5',\"'\"+degree+\"'\")\n",
    "\n",
    " #above replaces all value holders\n",
    " \n",
    " Itemstr = Item.item()\n",
    " if deciderDate > 0.5:#if the random gives a value higher than 50%, the line will include date\n",
    "    sqls = sqls.astype('str')+X6Sql#adds date to sql\n",
    "    Item = Item.str.replace(\"؟\",X6Text+\"؟\")#adds date to text\n",
    "   \n",
    " \n",
    " \n",
    " try:\n",
    "    if not newdata[0].str.contains(Item.item()).any():\n",
    "     \n",
    "     full.append(Itemstr) \n",
    "     newdata = pd.concat([newdata,Item])\n",
    "     newsql = pd.concat([newsql,sqls])\n",
    "     \n",
    "\n",
    " except:\n",
    "    full.append(Itemstr)\n",
    "    newdata = pd.concat([newdata,Item])\n",
    "    newsql = pd.concat([newsql,sqls])\n",
    "\n",
    "dt = pd.concat([newdata,newsql], axis = 1)#merges all text and sql to a single file\n",
    "dt.to_excel(r\"C:\\...\\full.xlsx\", index = False)#save file\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")#extract key from .env file\n",
    "!python openai tools fine_tunes.prepare_data -f \"full.xlsx\"#prepare the data. note the headers in full were changed to 'prompt' and 'completion' prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the training and validation set where the validation is 25%\n",
    "\n",
    "\n",
    "shuffler = pd.read_json('full_prepared.jsonl', lines=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    shuffler['prompt'], shuffler['completion'], random_state=48, test_size=0.25)\n",
    "\n",
    "Train= pd.concat([X_train, y_train], axis=1)\n",
    "Validate = pd.concat([X_val, y_val], axis=1)\n",
    "Train.to_excel(r\"C:\\....\\Full_no_stop_removed_training.xlsx\",index=False)#always saved in excel due to decoding issues\n",
    "Validate.to_excel(r\"C:\\...\\Full_no_stop_removed_validate.xlsx\",index=False)\n",
    "#note the absence of the testing set. It was made using a more varied template to enclude new keywords the program hasn't seen before\n",
    "#that was done to ensure the avoidance of overfitting. It was then prepared as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "stop = stopwords.words('arabic')#stopword extraction\n",
    "\n",
    "\n",
    "training = pd.read_json(r\"C:\\....\\Full_no_stop_removed_training.jsonl\", lines=True)#prepared using fine_tunes.prepare as above\n",
    "validation = pd.read_json(r\"C:\\...\\Full_no_stop_removed_validate.jsonl\", lines=True)\n",
    "\n",
    "training['prompt'] = training['prompt'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "validation['prompt'] = validation['prompt'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))#stopwords removal\n",
    "training.to_excel(r\"C:\\....\\Full_stop_removed_training.xlsx\",index=False)#always saved in excel due to decoding issues\n",
    "validation.to_excel(r\"C:\\...\\Full_stop_removed_validate.xlsx\",index=False)\n",
    "\n",
    "#again, everything was run through the preparer. this was for caution: to tripple check that everything was in the correct format\n",
    "#because the modules are time-consuming"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file upload\n",
    "\n",
    "tra=openai.File.create(file=open(r\"C:\\...\\Full_no_stop_removed_training_prepared.jsonl\", \"rb\"),purpose='fine-tune')\n",
    "val=openai.File.create(file=open(r\"C:\\...\\Full_no_stop_removed_validate_prepared.jsonl\", \"rb\"),purpose='fine-tune')\n",
    "print(tra)\n",
    "print(val)#look for the ID of the file for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.FineTune.create(training_file=\"file-idNum\", validation_file = \"file-idNum\",n_epochs = 5)\n",
    "#create the module, and retrieve the module ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!openai api fine_tunes.follow -i \"ft-idModule\" #check the status and retrieve module name\n",
    "#repeat for the files with stopwords removed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions = [0]*300#placed in a different cell as to only access when starting a new set (to keep the runtime values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "import pandas as pd\n",
    "df = pd.read_json(r\"C:\\...\\test_prepared.jsonl\", lines=True)\n",
    "\n",
    "from time import sleep\n",
    "for i in range(0,300):\n",
    "  response = openai.Completion.create(\n",
    "    model=\"modelName\",\n",
    "    prompt=df.iloc[i,:].get('prompt') ,\n",
    "    temperature=0.3,\n",
    "    max_tokens=200,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=[\"#\", \";\",\"->\",'\\n']\n",
    "  )\n",
    "  completions[i] = response['choices'][0]['text']\n",
    "  if (i%30==0):\n",
    "    sleep(60)\n",
    "    \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['completion'] = completions#cast the results to a dataset when complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('test complete no stop removed.json')\n",
    "df.to_excel('test complete no stop removed.xlsx')#save output. Repeat for model recovered from training set with removed stopwords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Measurment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "import pandas as pd\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "model_in = pd.read_excel('no stop.xlsx')#manually checked and reformatted from previous step to keep only the part we want to measure in the excel\n",
    "refr=  pd.read_excel('test.xlsx')#likewise...\n",
    "rouge.get_scores(model_in, refr, avg=True)#recover and print scores\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82582612eaa5aa67ed103a0414b73eeaa6107dd390ad45d21b5737bd6613de0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
